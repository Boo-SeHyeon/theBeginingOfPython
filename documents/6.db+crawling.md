# 안전하게 데이터를 저장하자 + 웹에서 데이터를 긁어오자
이번 차시에서는 __정보__ 와 __데이터베이스__ 의 개념을 간단히 잡고 웹에서 자료를 수집하는 __크롤링__ 실습을 진행합니다.  

## 데이터베이스와 정보
### 데이터? 정보?  
정보와 데이터(자료)를 같은 것으로 생각하고 있는 사람들이 생각보다 많습니다.   
하지만 이 둘은 엄연히 다른 개념입니다.  
+ _데이터_ : 현실세계에서 벌어지는 일들을 단순한 방법으로 관찰하고 측정해서 얻은 사실이나 값
+ _정보_ : 데이터(자료)를 처리해서 얻는, 실제 문제해결이나 의사결정에 도움이 되는 유의미한 결과   
   
예를 들어봅시다.  
여러분이 마스크 제조회사 직원이고 10년동안 월간 마스크 판매량을 조사했다고 가정합시다.   
조사한 값들은 데이터(자료)입니다.  
그런데 이 값들을 처리하여 __'마스크는 여름보다 겨울에 잘 팔린다'__ 라는 유의미한 결과를 얻어내었습니다.   
이는 정보라고 할 수 있습니다.   
이 정보를 추후 계절별 마스크 생산량을 결정하거나 다른 문제를 해결할 때 근거로 사용할 수 있을 것입니다.  
  
감이 조금 오시나요?  
정리하자면 우리는 일상생활에서 데이터들을 수집하고, 이를 추출하고 분석하여   
문제해결에 도움이 되는 정보를 알아냅니다.  

### 데이터베이스(DB)와 DBMS
다음은 _데이터베이스_ 에 대해 알아봅시다. 흔히 줄여서 DB(DataBase)라고 많이 표현합니다.  
데이터로부터 정보를 추출하기 위해서는 어딘가에 저장이 되어있어야 하겠죠?  
데이터베이스는 __여러 사람이 공유하여 사용할 목적으로 체계화해 통합, 관리하는 데이터의 집합__ 을 의미합니다.  
한마디로 데이터를 얻기 위해 효율적으로 저장된 집합체라고 표현할 수 있습니다.  

그리고 이러한 데이터베이스를 쉽게 만들고 관리하는 여러가지 프로그램들이 모여서 하나의 시스템으로 갖춰진  
것을 DBMS, 데이터베이스관리시스템이라고 부릅니다. 흔히 말하는 Oracle, MySQL, SQLServer등이 이에 속합니다.
대부분의 DB들이 DBMS를 통해 만들어지고 운영되기 때문에 DB와 DBMS가 같은 의미로 사용되는 경우가 있지만  
이 둘도 정보와 데이터처럼 엄연히 다른 개념입니다.  
 
지금까지 데이터와 정보, DB에 대해 살펴보았습니다.  
요즘같은 정보사회에서는 데이터베이스를 활용, 다양한 데이터들을 융합하여 새로운 개념을 창출함으로써  
그 가치를 증대시키는 일의 중요성이 높아지고 있습니다. 데이터베이스 전문가까진 아니더라도  
개념 정도는 기억하고 계시면 좋을 것 같습니다. :)

## 크롤링 실습 
이제 웹에서 원하는 자료를 가져오는 크롤링 실습을 해봅시다.  

### 크롤링이란(+ 매크로)?
웹 상의 수많은 데이터를 일일이 눈으로 보면서 찾아와야한다면 굉장히 번거롭겠죠?  
프로그래밍을 통해 자동화하면 굉장히 좋을 것 같지 않나요?  
  
누군가 우리보다 먼저 비슷한 생각을 하였고 이 아이디어는 웹 크롤러의 형태로 구현되었습니다.
웹 페이지들이 포함하고 있는 다양한 데이터를 웹 크롤러를 통해 쉽게 가져올 수 있습니다 :)  

_Web Crawling_ 혹은 _Web Scraping_ 은 컴퓨터 소프트웨어 기술로 웹사이트들에서 원하는 데이터를 추출하는 것을 의미합니다.  
그리고 이 작업을 수행하는 프로그램을 _웹 크롤러(Web Crawler)_ 라고 합니다.  
비트코인의 시세를 가져온다거나, 영화 순위 사이트에서 상위 10개의 영화 제목 데이터를 가져오는 것 등을    
예시로 들 수 있습니다.  
다른 활용방안으로 머신러닝을 위한 빅데이터 수집에도 사용할 수 있습니다. 만약 여러분의 이미지 분류 모델에    
사과 이미지를 학습시키기 위한 이미지 자료를 마련하길 원한다면, 구글에서 사과를 검색하고 해당하는 이미지들을 쭉 모아오도록     
웹 크롤러를 프로그래밍하면 됩니다

### 크롬 개발자 도구를 활용한 웹 정적 리버싱  
안타까운 소식이 하나 있습니다.  
여러분이 웹 크롤러 프로그램을 작성하기 위해서는 원하는 정보가 웹 페이지의 어느 부분에 있는지 알아야 한다는 점입니다.  
물론 웹페이지의 소스 전체를 들고 오는 것은 웹페이지의 구조를 몰라도 가능하지만, 특정 데이터만을 들고 오는 크롤러를  
만들기 위해서는 여러분의 목표 사이트의 구조를 뜯어볼 필요가 있습니다.  
   
하지만 너무 걱정하지 마세요!  
크롬 브라우저가 제공하는 개발자 도구를 활용하면 위의 작업을 손쉽게 할 수 있습니다.   
그럼 지금부터 실제 크롤링을 하기 앞서 크롬 개발자도구를 이용해 일종의 리버싱 작업을 하는 방법을 살펴보겠습니다.  
(_리버싱_ : __소프트웨어 분야에서 해당 프로그램의 구조, 기능, 동작 등의 원리를 역으로 따라가며 이해하고 분석하여   
부족한 부분이 있거나 추가 되었으면 하는 새로운 기능 등을 추가하는 전체적 행위__)

* HTML과 CSS의 구조는 해당 문서에서 다루지 않습니다. 관련내용은 WWW 레포지토리의 해당 문서를 참고해주세요.  

1. 먼저 크롬 브라우저를 실행시키고 네이버로 들어가주세요.
![img]()
2. 키보드의 F12를 누르면 크롬 개발자 도구가 나타나는 것을 확인할 수 있습니다.  

3. Elements를 클릭하면 여러분이 보고 있는 웹페이지의 소스를 볼 수 있습니다.

4. 소스 코드에 마우스를 올려보시기 바랍니다. HTML 파일에서 여러분의 마우스가 가리키고 있는 지점이  
   브라우저에서 어떻게 보이는지 바로 확인할 수 있습니다.  
   
5. 반대도 가능합니다. Elements 왼쪽에 마우스 커서 모양의 아이콘을 클릭해주세요. 그리고 브라우저에서 보여지고 있는  
   화면으로 마우스를 이동시켜보세요. 마우스가 있는 부분이 HTML 소스의 어느 부분인지 확인할 수 있습니다.  
   



















 
 
+ 데이터베이스 및 정보, 일상에서 사용할 크롤링(개념) + 내 손으로 만져 보는 크롤링(실습)
  
  - 데이터베이스 → 정보사회에서 융합을 통한 새로운 개념 창출로 가치 증대(완)
  - 귀찮은 일 자동화하기(매크로?) (완)
  - 크롤링 예시 및 활용 (완)
  - 크롬 개발자 도구를 활용한 웹 정적 리버싱(네이버 실시간 검색어) → 웹 개발 및 디버깅
  - 네이버 실시간 검색어 가져오기([`naver_rank.py`](../6.db+crawling/naver_rank.py)) 
  - melon 실시간 차트 가져오기([`melon_rank.py`](../6.db+crawling/melon_rank.py))